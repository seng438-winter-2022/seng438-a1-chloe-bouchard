>   **SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group \#:       | 8  |
|-----------------|---|
| Student Names:  | Kaitlin Culligan  |
|                 | Kunal Dhawan  |
|                 | Chloe Bouchard  |
|                 | Jacob Lansang  |

**Table of Contents**

(When you finish writing, update the following list using right click, then
“Update Field”)

[1 Introduction	1](#_Toc439194677)

[2 High-level description of the exploratory testing plan	1](#_Toc439194678)

[3 Comparison of exploratory and manual functional testing	1](#_Toc439194679)

[4 Notes and discussion of the peer reviews of defect reports	1](#_Toc439194680)

[5 How the pair testing was managed and team work/effort was
divided	1](#_Toc439194681)

[6 Difficulties encountered, challenges overcome, and lessons
learned	1](#_Toc439194682)

[7 Comments/feedback on the lab and lab document itself	1](#_Toc439194683)

# Introduction


In this lab, we are testing a software using different testing approaches to find defects. The testing approaches include exploratory testing, manual scripted testing, and regression testing. By testing a software ATM system, we will apply these testing approaches in order to get more familiar with software testing as well as a bug tracking system called Backlog.

Before this lab, we were aware that exploratory testing was a form of unscripted testing where the test are designed and executed at the same time. The idea of exploratory testing is to create "realistic" scenarios and using those scenarios to test the software. This approach is human based and can test simple functionalities or large sets of sequences. In contrast, manual functional testing is a scripted testing approach that is usually written by the tester themselves. This form of testing follows a specific path and there is no deviation from this path. Regression testing is the process of redoing manual scripted testing on an updated version of the software to see if any previous bugs were solved. In addition to making sure new bugs were not added in the updated version, regression testing checks to make sure that previously fixed bugs were not accidentally reintroduced.

# High-level description of the exploratory testing plan

Exploratory testing was the first technique used to detect bugs and defects in the ATM. Although exploratory testing is seen as unplanned, there was a very in-depth procedure that was followed. As the lab manual described, the testing was done in two teams. Within a team, the two members decided generally which type of functionality they were planning to test. For 30 minutes, one of the team members shared their screen with the other and intuitively tested out features, while maintaining the theme of the pre-decided functionality type. Simultaneously, the other team member was keeping track of each step, in order to be able to re-create it, if needed. When a defect was found, the team member in charge of testing double checked the bug a second time and confirmed with the other team member that it was indeed a defect. The team member in charge of supervising then submitted the bugs to the backlog project. Once the 30 minutes was elapsed, the team members switched roles and repeated the process for another 30 minutes before moving on to manual testing.  We tested in a breadth-first manner, trying to test all functionalities slightly rather than a few in depth. Test cases were based on the most frequently used paths users could take.


# Comparison of exploratory and manual functional testing

-   Note that you need to submit a report generated by your defect tracking
    system, containing all defects recorded in the system.
    
When actually testing the ATM using both exploratory and manual scripted testing, we can see that they are completely different in their approach. Exploratory testing felt very unstructured and was not guided by any strict guidelines. Therefore, testers were able to use the ATM properly or try odd sequences of inputs in order to find bugs in unique ways. This method of testing allowed the testers to find more "hidden" bugs by adding several steps. Manual scripted testing was very guided and strict in terms of what inputs you could use. The ATM would need to be in a very specific state before you could test certain inputs. Any deviation from this structure would make the initial system state to be tested to be incorrect. 

# Notes and discussion of the peer reviews of defect reports

The peer reviews of defect reports were very useful. They helped to confirm that any bugs we discovered were indeed defects with the system under test, and not some anomaly as a result of the machine the system was being run on. The use of peer reviews also helped to ensure that defects were correctly documented on Backlog. There were several instances where defect reports could have been written better originially, were a duplicate report, or were otherwise incorrectly reported on Backlog. In these cases, the use of peer review caught and corrected these errors where they would not have been otherwise.

# How the pair testing was managed and team work/effort was divided 

Team work during each part of the lab was split evenly between each group member. Each group member spent about 30 minutes doing exploratory testing on the the ATM system and recorded any defects to Backlog. Manual scripted testing was split evenly between group members, where each group member would handle 10 test cases in Appendix C. Similarly for regression testing, each group member went over the bugs they found during manual functional testing in version 1.1 of the ATM system.

# Difficulties encountered, challenges overcome, and lessons learned

During this lab, some group members found it difficult to remember the sequences it took to reach a bug, specifically during exploratory testing. This was easily overcome by examining the ATMs log and by listing the sequence of events taken as the tester navigates the system. It was also somewhat challenging to get familiar with Backlog, but this was overcome as we began to record our bug reports over time. During exploratory testing, it was tough to not list duplicate reports as some group members were finding the same defects as other group members. In order to prevent duplicate reports, we learned to search through our bug reports before posting any new reports. 

# Comments/feedback on the lab and lab document itself

The timing of the TA demonstration was not well planned out. Unfortunately, our group did not have the chance to present our bugs to the TA during our scheduled lab time, due to delays. Because of this, we were not able to receive any feedback to improve the quality of our bugs entries and our report.
